{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IS7033-NLPTransferLearning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daveDoesData/IS7033/blob/master/IS7033_NLPTransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lVmN9y9uhWyJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Pv2bjnMriFWP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is my first attempt at transfer learning with NLP.\n",
        "At this time, I am able to get ELMo's word embedings out from the final layer of the ELMo network.\n",
        "Once , I get over the shape hurdel (reading paper and examples again) this information will feed into a simple one layer nn created with pytorch to classify text documents. \n",
        "\n",
        "I have included a visual representation of the notebook's current state below:\n",
        "\n",
        "![alt text](https://media.giphy.com/media/DEEG4drtolbGM/giphy.gif)"
      ]
    },
    {
      "metadata": {
        "id": "aG3k_sBkQf70",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### So, What is ELMo (Besides Adorable)?\n",
        "\n",
        "{Better description to be added}\n",
        "\n",
        "ELMo is one of the newer word embedings options avialable to researchers and practioners alike. Produced by the Allen NLP institute, ELMo goes beyond traditional word embeddings becasue with ELMo context matters. ELMo cannot provide a word embeding without seeing the whole sentence. Unfortunately for ELMo, BERT showed up shortly after ELMo and stole the spotlight. However, ELMo is a sensible place to start when learning deep word representation models since it utilizes more \"traditional\" LSTMs instead of transformers like BERT. \n",
        "\n",
        "![https://jalammar.github.io/illustrated-bert/](https://jalammar.github.io/images/elmo-forward-backward-language-model-embedding.png)\n",
        "\n",
        "![https://jalammar.github.io/illustrated-bert/](https://jalammar.github.io/images/elmo-embedding.png)\n",
        "source: https://jalammar.github.io/illustrated-bert/"
      ]
    },
    {
      "metadata": {
        "id": "9mRqKRfpQhuM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Development"
      ]
    },
    {
      "metadata": {
        "id": "6g5XLbPyZzCT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To get started, let's add in all of the extra goodies we'll need outside of colab's starter set."
      ]
    },
    {
      "metadata": {
        "id": "ERJbxF1K-C0l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "pip install allennlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2kffAu-lcSz",
        "colab_type": "code",
        "outputId": "5dc706a2-20cf-4d18-b96b-f841bf6337ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from allennlp.commands.elmo import ElmoEmbedder, batch_to_ids\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "uolms87paFFl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stance Data Set"
      ]
    },
    {
      "metadata": {
        "id": "9QQf27P6Nms_",
        "colab_type": "code",
        "outputId": "eeea44c4-7383-4174-ffdb-6f503894e15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wget https://saifmohammad.com/WebDocs/stance-data-all-annotations.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-02 02:02:28--  https://saifmohammad.com/WebDocs/stance-data-all-annotations.zip\n",
            "Resolving saifmohammad.com (saifmohammad.com)... 192.185.17.122\n",
            "Connecting to saifmohammad.com (saifmohammad.com)|192.185.17.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 320467 (313K) [application/zip]\n",
            "Saving to: ‘stance-data-all-annotations.zip’\n",
            "\n",
            "     0K .......... .......... .......... .......... .......... 15% 1.59M 0s\n",
            "    50K .......... .......... .......... .......... .......... 31% 1.59M 0s\n",
            "   100K .......... .......... .......... .......... .......... 47% 77.7M 0s\n",
            "   150K .......... .......... .......... .......... .......... 63% 1.62M 0s\n",
            "   200K .......... .......... .......... .......... .......... 79% 66.5M 0s\n",
            "   250K .......... .......... .......... .......... .......... 95%  126M 0s\n",
            "   300K .......... ..                                         100% 77.7M=0.09s\n",
            "\n",
            "2019-04-02 02:02:28 (3.27 MB/s) - ‘stance-data-all-annotations.zip’ saved [320467/320467]\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9KX8kFQZN3_y",
        "colab_type": "code",
        "outputId": "67774ffc-23a0-469e-e073-baa3e39fba13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "unzip stance-data-all-annotations.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  stance-data-all-annotations.zip\n",
            "   creating: data-all-annotations/\n",
            "  inflating: data-all-annotations/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data-all-annotations/\n",
            "  inflating: __MACOSX/data-all-annotations/._.DS_Store  \n",
            "  inflating: data-all-annotations/readme.txt  \n",
            "  inflating: data-all-annotations/testdata-taskA-all-annotations.txt  \n",
            "  inflating: __MACOSX/data-all-annotations/._testdata-taskA-all-annotations.txt  \n",
            "  inflating: data-all-annotations/testdata-taskA-ids.txt  \n",
            "  inflating: __MACOSX/data-all-annotations/._testdata-taskA-ids.txt  \n",
            "  inflating: data-all-annotations/testdata-taskB-all-annotations.txt  \n",
            "  inflating: __MACOSX/data-all-annotations/._testdata-taskB-all-annotations.txt  \n",
            "  inflating: data-all-annotations/testdata-taskB-ids.txt  \n",
            "  inflating: __MACOSX/data-all-annotations/._testdata-taskB-ids.txt  \n",
            "  inflating: data-all-annotations/trainingdata-all-annotations.txt  \n",
            "  inflating: __MACOSX/data-all-annotations/._trainingdata-all-annotations.txt  \n",
            "  inflating: data-all-annotations/trainingdata-ids.txt  \n",
            "  inflating: __MACOSX/data-all-annotations/._trainingdata-ids.txt  \n",
            "  inflating: data-all-annotations/trialdata-all-annotations.txt  \n",
            "  inflating: __MACOSX/data-all-annotations/._trialdata-all-annotations.txt  \n",
            "  inflating: data-all-annotations/trialdata-ids.txt  \n",
            "  inflating: __MACOSX/data-all-annotations/._trialdata-ids.txt  \n",
            "  inflating: __MACOSX/._data-all-annotations  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8dUdK1o6aLTd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainEvalCombo = pd.read_csv('data-all-annotations/trainingdata-all-annotations.txt', delimiter='\\t', header=0, encoding = 'latin-1')\n",
        "testTaskA = pd.read_csv('data-all-annotations/testdata-taskA-all-annotations.txt', delimiter='\\t', header=0, encoding = 'latin-1')\n",
        "testTaskB = pd.read_csv('data-all-annotations/testdata-taskB-all-annotations.txt', delimiter='\\t', header=0, encoding = 'latin-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C2Dvr0UwUYnE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_tweets(text):\n",
        "    no_ascii = ''.join(i for i in text if ord(i) < 128)\n",
        "    no_alphanum = re.sub(r'[^a-zA-Z0-9 ]', '', no_ascii)\n",
        "    lower_txt = no_alphanum.lower()\n",
        "    return lower_txt\n",
        "\n",
        "trainEvalCombo['Tweet'] = trainEvalCombo['Tweet'].apply(clean_tweets)\n",
        "testTaskA['Tweet'] = testTaskA['Tweet'].apply(clean_tweets)\n",
        "testTaskB['Tweet'] = testTaskB['Tweet'].apply(clean_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E3iu5BN9pWMt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1776)\n",
        "spiter = np.random.rand(len(trainEvalCombo)) < 0.8\n",
        "trainDF = trainEvalCombo[spiter]\n",
        "evalDF = trainEvalCombo[~spiter]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qz0t26UPUNCc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainX_words = [words.split() for words in trainDF['Tweet']] \n",
        "evalX_words = [words.split() for words in evalDF['Tweet']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nC5QXrex41LO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainY_string = trainDF['Stance']\n",
        "convert_label_to_int = LabelEncoder()\n",
        "trainY = convert_label_to_int.fit_transform(trainY_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TLCoFCP77xb6",
        "colab_type": "code",
        "outputId": "e4416176-d37f-4a39-a1bc-17c5c2da258f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(trainY[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ulr9FXRf75mr",
        "colab_type": "code",
        "outputId": "583fec95-2f4c-4dd1-b3ee-d77d8a1b0129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "print(trainY_string[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     AGAINST\n",
            "1     AGAINST\n",
            "2     AGAINST\n",
            "3     AGAINST\n",
            "4     AGAINST\n",
            "5     AGAINST\n",
            "6     AGAINST\n",
            "7       FAVOR\n",
            "10      FAVOR\n",
            "11    AGAINST\n",
            "Name: Stance, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bMFr4AITWfsw",
        "colab_type": "code",
        "outputId": "5a183b3d-9e0b-4cc5-ba92-db26ccff23de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(trainX_words[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dear', 'lord', 'thank', 'u', 'for', 'all', 'of', 'ur', 'blessings', 'forgive', 'my', 'sins', 'lord', 'give', 'me', 'strength', 'and', 'energy', 'for', 'this', 'busy', 'day', 'ahead', 'blessed', 'hope', 'semst']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PS7Sxz-leN9H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ELMo\n",
        "\n",
        "### Using ELMo interactively\n",
        "You can use ELMo interactively (or programatically) with iPython. The allennlp.commands.elmo.ElmoEmbedder class provides the easiest way to process one or many sentences with ELMo, but it returns numpy arrays so it is meant for use as a standalone command and not within a larger model. For example, if you would like to learn a weighted average of the ELMo vectors then you need to use allennlp.modules.elmo.Elmo instead.\n",
        "\n",
        "The ElmoEmbedder class returns three vectors for each word, each vector corresponding to a layer in the ELMo LSTM output. The first layer corresponds to the context insensitive token representation, followed by the two LSTM layers. See the ELMo paper or follow up work at EMNLP 2018 for a description of what types of information is captured in each layer.\n",
        "\n",
        "source: https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md\n",
        "\n",
        "The ``elmo`` subcommand allows you to make bulk ELMo predictions.\n",
        "Given a pre-processed input text file, this command outputs the internal\n",
        "layers used to compute ELMo representations to a single (potentially large) file.\n",
        "The input file is previously tokenized, whitespace separated text, one sentence per line.\n",
        "The output is a hdf5 file (<http://docs.h5py.org/en/latest/>) where, with the --all flag, each\n",
        "sentence is a size (3, num_tokens, 1024) array with the biLM representations.\n",
        "For information, see \"Deep contextualized word representations\", Peters et al 2018.\n",
        "https://arxiv.org/abs/1802.05365\n",
        "\n",
        "source: https://github.com/allenai/allennlp/blob/master/allennlp/commands/elmo.py\n"
      ]
    },
    {
      "metadata": {
        "id": "wVbyG0ageJ6W",
        "colab_type": "code",
        "outputId": "566742f1-061e-4c3d-f084-549f91c12d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "elmo = ElmoEmbedder()\n",
        "tokens = [\"I\", \"ate\", \"an\", \"apple\", \"for\", \"breakfast\"]\n",
        "vectors = elmo.embed_sentence(tokens)\n",
        "\n",
        "assert(len(vectors) == 3) # one for each layer in the ELMo output\n",
        "assert(len(vectors[0]) == len(tokens)) # the vector elements correspond with the input tokens\n",
        "\n",
        "import scipy\n",
        "vectors2 = elmo.embed_sentence([\"I\", \"ate\", \"a\", \"carrot\", \"for\", \"breakfast\"])\n",
        "scipy.spatial.distance.cosine(vectors[2][3], vectors2[2][3]) # cosine distance between \"apple\" and \"carrot\" in the last layer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18020617961883545"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "9W3uSkzUqgmn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "elmo = ElmoEmbedder(options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "                   ,weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "                   ,cuda_device = 0)\n",
        "#trainX_vectors = elmo.embed_sentences([trainX_words], batch_size = 100)\n",
        "trainX_vectors = [elmo.embed_sentence(tokens) for tokens in trainX_words]\n",
        "trainX_ELMo_vectors_last_layer = [vectors[2] for vectors in trainX_vectors]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2qLeZZjJQ4t5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Allen NLP elmo.embed_sentences function is lazy and it just creates a generator instead of the list of numpy arrays. "
      ]
    },
    {
      "metadata": {
        "id": "j_GKs3fxDCOb",
        "colab_type": "code",
        "outputId": "94bf286d-9a67-4a48-d574-ecdbad0a2a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(trainX_ELMo_vectors_last_layer[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "iinH8_ZODRTt",
        "colab_type": "code",
        "outputId": "00cd48aa-aa23-4f45-d796-3fde7d6c7800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "cell_type": "code",
      "source": [
        "trainX_ELMo_vectors_last_layer[0]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.17908666, -1.574388  ,  0.9519706 , ...,  0.19991188,\n",
              "         0.41037235,  0.92734903],\n",
              "       [ 0.44663948, -0.6578803 ,  0.53522146, ...,  0.29883933,\n",
              "         2.2307096 ,  0.03350666],\n",
              "       [ 1.4313195 , -1.4037013 , -0.43510285, ...,  0.11510789,\n",
              "         1.6071985 , -0.720706  ],\n",
              "       ...,\n",
              "       [ 0.13420373, -0.34323138,  0.5758524 , ..., -0.19494513,\n",
              "         0.4945613 ,  0.19315866],\n",
              "       [-0.0363926 , -0.4113907 ,  0.19109306, ...,  0.32084963,\n",
              "         1.2030481 , -0.11308239],\n",
              "       [-0.13918735, -0.16288519,  0.682714  , ...,  0.11081195,\n",
              "         0.28356946,  0.31483012]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "kwK6L-v019k-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainX_ELMo_vectors_last_layer = [vectors[2] for vectors in trainX_vectors]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ghzTOLW_1_lf",
        "colab_type": "code",
        "outputId": "9b787904-3e42-4ef8-c5a3-d129ce4b397d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(trainX_ELMo_vectors_last_layer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "6eokv-G4aHoL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import torch.utils.data as utils\n",
        "\n",
        "#tensor_x = []\n",
        "#for sentence in trainX_ELMo_vectors_last_layer:\n",
        "#  sent_output_embed = torch.stack([torch.Tensor(i) for i in sentence])\n",
        "#  tensor_x.append(sent_output_embed)\n",
        "#tensor_y = torch.from_numpy(trainY)\n",
        "\n",
        "#my_dataset = utils.TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "#my_dataloader = utils.DataLoader(my_dataset) # create your dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}